{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Paws, an AWS SDK for R","text":""},{"location":"#overview","title":"Overview","text":"<p>Paws is a Package for Amazon Web Services in R. Paws provides access to the full suite of AWS services from within R.</p> <p>Visit our home page to see online documentation.</p> <p>Disclaimer: Paws is not a product of or supported by Amazon Web Services.</p>"},{"location":"#installation","title":"Installation","text":"<p>Install Paws using:</p> <pre><code>install.packages(\"paws\")\n</code></pre> <p>If you are using Linux, you will need to install the following OS packages:</p> <ul> <li>Debian/Ubuntu: <code>libcurl4-openssl-dev libssl-dev libxml2-dev</code></li> <li>CentOS/Fedora/Red Hat: <code>libcurl-devel libxml2-devel openssl-devel</code></li> </ul> <p>Or install the development version from r-universe: <pre><code># Enable repository from paws-r\noptions(repos = c(\npawsr = 'https://paws-r.r-universe.dev',\nCRAN = 'https://cloud.r-project.org')\n)\n# Download and install paws in R\ninstall.packages('paws')\n</code></pre></p>"},{"location":"#credentials","title":"Credentials","text":"<p>You'll need to set up your AWS credentials and region. Paws supports setting these per-service, or using R and OS environment variables, AWS credential files, and IAM roles. See articles/credentials.md for more info.</p> <p>In the example below, we set them with R environment variables.</p> <p>Warning: Do not save your credentials in your code, which could reveal them to others. Use one of the other methods above instead. See also RStudio's best practices for securing credentials.</p> <pre><code>Sys.setenv(\nAWS_ACCESS_KEY_ID = \"abc\",\nAWS_SECRET_ACCESS_KEY = \"123\",\nAWS_REGION = \"us-east-1\"\n)\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>To use a service, create a client. All of a service's operations can be accessed from this object.</p> <pre><code>ec2 &lt;- paws::ec2()\n</code></pre> <p>Launch an EC2 instance using the <code>run_instances</code> function.</p> <pre><code>resp &lt;- ec2$run_instances(\nImageId = \"ami-f973ab84\",\nInstanceType = \"t2.micro\",\nKeyName = \"default\",\nMinCount = 1,\nMaxCount = 1,\nTagSpecifications = list(\nlist(\nResourceType = \"instance\",\nTags = list(\nlist(Key = \"webserver\", Value = \"production\")\n)\n)\n)\n)\n</code></pre> <p>List all of your instances with <code>describe_instances</code>.</p> <pre><code>ec2$describe_instances()\n</code></pre> <p>Shut down the instance you started with <code>terminate_instances</code>.</p> <pre><code>ec2$terminate_instances(\nInstanceIds = resp$Instances[[1]]$InstanceId\n)\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>You can browse all available services by looking at the package documentation.</p> <pre><code>help(package = \"paws\")\n</code></pre> <p>You can also jump to a specific service and see all its operations.</p> <pre><code>?paws::ec2\n</code></pre> <p>RStudio's code completion will show you the available services, their operations, and each operation's parameters.</p> <p></p> <p>There are also examples for EC2, S3, SQS, SNS, DynamoDB, Lambda, Batch, and Comprehend.</p>"},{"location":"#related-packages","title":"Related packages","text":"<ul> <li><code>cognitoR</code> provides   authentication for Shiny applications using Amazon Cognito.</li> <li><code>noctua</code> is an interface to the Athena serverless interactive query service, which allows you to query files stored in S3 using SQL or <code>dplyr</code>.</li> <li><code>R6sagemaker</code> is an interface to the SageMaker machine learning service, designed to work like the Python SageMaker SDK.</li> <li><code>redshiftTools</code> is a collection of tools for working with the Redshift data warehouse service, such as performing bulk uploads.</li> <li><code>stepfunctions</code> is an SDK for building machine learning workflows and pipelines on AWS using the Step Functions service.</li> </ul>"},{"location":"#examples-tutorials-and-workshops","title":"Examples, tutorials, and workshops","text":"<ul> <li>AWS AI Services for R Users shows how to use AWS to add deep learning capabilities like image recognition, text translation, and text-to-speech conversion to R and Shiny applications.</li> <li>Using Amazon Rekognition from R is an end to end example of how to build and deploy a model to detect Nike swooshes in images using the Rekognition computer vision service.</li> </ul>"},{"location":"#credits","title":"Credits","text":"<p>API specifications from AWS SDK for JavaScript; design based on AWS SDK for Go.</p> <p>Logo by Hsinyi Chen.</p> <p>Home page design and cheat sheet by Mara Ursu.</p> <p>Supported by the AWS Open Source promotional credits program.</p>"},{"location":"articles/credentials/","title":"Setting Credentials and Region","text":"<ul> <li>Set credentials</li> <li>Set credentials for all services with environment variables</li> <li>Get credentials from the AWS shared credentials file</li> <li>Set credentials for an individual service</li> <li>Get credentials from an EC2 instance or container role</li> <li>Get credentials from a command line process</li> <li>Assume a role with credentials from the environment or an instance/container role</li> <li>Assume a role with credentials from another profile</li> <li>Use multifactor authentication when assuming a role</li> <li>Use AWS Single Sign-On (SSO)</li> <li>Set region</li> <li>Set region for all services with an environment variable</li> <li>Get region from the AWS config file</li> <li>Set region for an individual service</li> <li>Set profile</li> <li>Reference</li> <li>Credential and option locations and priority</li> <li>Service settings</li> <li>Environment variables</li> <li>Shared credentials file</li> <li>Config file</li> </ul>"},{"location":"articles/credentials/#set-credentials","title":"Set credentials","text":"<p>In order to use AWS APIs, you must provide your credentials.</p> <p>Below are examples of how to set your credentials for common scenarios. For a reference to all available options, see the reference section.</p>"},{"location":"articles/credentials/#set-credentials-for-all-services-with-environment-variables","title":"Set credentials for all services with environment variables","text":"<p>You can set credentials for all services using environment variables. Paws will look for credentials in both OS or R environment variables.</p> <p>You can use R to set credentials with the following command:</p> <pre><code>Sys.setenv(\nAWS_ACCESS_KEY_ID = \"your AWS access key\",\nAWS_SECRET_ACCESS_KEY = \"your AWS secret key\"\n)\n</code></pre> <p>If you have a session token from temporary security credentials, you can set it and its expiration time in environment variables <code>AWS_SESSION_TOKEN</code> and <code>AWS_CREDENTIAL_EXPIRATION</code> (optional):</p> <pre><code>Sys.setenv(\nAWS_ACCESS_KEY_ID = \"your AWS access key\",\nAWS_SECRET_ACCESS_KEY = \"your AWS secret key\",\nAWS_SESSION_TOKEN = \"your session token\",\nAWS_CREDENTIAL_EXPIRATION = \"ISO 8601 expiration time\"\n)\n</code></pre> <p><code>AWS_CREDENTIAL_EXPIRATION</code> must be an ISO 8601 formatted date string. If <code>AWS_CREDENTIAL_EXPIRATION</code> is not provided (i.e., only the temporary values for <code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code>, and <code>AWS_SESSION_TOKEN</code> are provided), then the expiration time is assumed to be <code>Inf</code>.</p>"},{"location":"articles/credentials/#get-credentials-from-the-aws-shared-credentials-file","title":"Get credentials from the AWS shared credentials file","text":"<p>You can set credentials for all services using the AWS shared credentials file in <code>~/.aws/credentials</code>.</p> <p>The credentials file should be in INI format and should look like:</p> <pre><code>[my-profile]\naws_access_key_id=your AWS access key\naws_secret_access_key=your AWS secret key\n</code></pre> <p>If you put these settings in a profile other than <code>default</code>, you will need to specify which profile to use; see set profile.</p> <p>You can specify another location for the AWS shared credentials file using environment variable <code>AWS_SHARED_CREDENTIALS_FILE</code>.</p>"},{"location":"articles/credentials/#set-credentials-for-an-individual-service","title":"Set credentials for an individual service","text":"<p>You can set credentials for an individual service by specifying them as arguments when you create the service object. These take precedence over credentials set using any other method.</p> <pre><code>svc &lt;- paws::svc(\nconfig = list(\ncredentials = list(\ncreds = list(\naccess_key_id = \"your AWS access key\",\nsecret_access_key = \"your AWS secret key\"\n)\n)\n)\n)\n</code></pre> <p>In this example, <code>paws::svc</code> is a placeholder for an AWS service. Use a specific service instead, for example, <code>paws::s3</code>. Paws supports having multiple service objects with different credentials.</p> <p>If you have a session token from temporary security credentials, you can provide it and its expiration time to <code>session_token</code> and <code>expiration</code>:</p> <pre><code>svc &lt;- paws::svc(\nconfig = list(\ncredentials = list(\ncreds = list(\naccess_key_id = \"your AWS access key\",\nsecret_access_key = \"your AWS secret key\",\nsession_token = \"your session token\",\nexpiration = as.POSIXct(\"2001-02-03 04:05:06\")\n)\n)\n)\n)\n</code></pre> <p><code>expiration</code> must be a <code>POSIXct</code> date-time or able to be compared with them.</p> <p>Additionally, anonymous credentials may be used (e.g., before calling <code>assume_role_with_web_identity()</code> on an STS service) <pre><code>svc &lt;- paws::svc(config = list(credentials = list(anonymous = TRUE)))\n</code></pre></p>"},{"location":"articles/credentials/#get-credentials-from-an-ec2-instance-or-container-role","title":"Get credentials from an EC2 instance or container role","text":"<p>If you are running R on an EC2 instance or in a container on AWS (ECS or EKS) with an  attached IAM role, Paws will automatically use the credentials from the attached role.</p>"},{"location":"articles/credentials/#get-credentials-from-a-command-line-process","title":"Get credentials from a command line process","text":"<p>You can get credentials from a command line process by specifying the process to run in <code>credential_process</code> in the AWS config file.</p> <pre><code>[profile my-profile]\ncredential_process=/opt/aws/get_credentials\n</code></pre> <p>The credential process is a command that must return JSON output that looks like the following:</p> <pre><code>{\n  \"Version\": 1,\n  \"AccessKeyId\": \"your AWS access key\",\n  \"SecretAccessKey\": \"your AWS secret access key\",\n  \"SessionToken\": \"your session token\",\n  \"Expiration\": \"ISO8601 expiration time\"\n}\n</code></pre> <p>If you put this setting in a config profile other than <code>default</code>, you will need to specify which profile to use; see set profile.</p> <p>The default location for the AWS config file is <code>~/.aws/config</code>. You can specify another location using environment variable <code>AWS_CONFIG_FILE</code>.</p>"},{"location":"articles/credentials/#assume-a-role-with-credentials-from-the-environment-or-an-instancecontainer-role","title":"Assume a role with credentials from the environment or an instance/container role","text":"<p>You can assume a role, using initial credentials provided by environment variables or by an EC2 instance or container role. To do this, specify in the AWS config file the role to assume in <code>role_arn</code> and the source of the credentials in <code>credential_source</code>.</p> <pre><code>[profile my-profile]\nrole_arn=arn:aws:iam::123456789012:role/my-role-name\ncredential_source=Environment\n</code></pre> <p><code>credential_source</code> can have one of three values:</p> <ul> <li> <p><code>Environment</code> \u2013 Specifies that the SDK is to retrieve source credentials     from environment variables.</p> </li> <li> <p><code>Ec2InstanceMetadata</code> \u2013 Specifies that the SDK is to use the IAM role     attached to the EC2 instance profile to get source credentials.</p> </li> <li> <p><code>EcsContainer</code> \u2013 Specifies that the SDK is to use the IAM role attached     to the ECS container as source credentials.</p> </li> </ul> <p>If you put these settings in a config profile other than <code>default</code>, you will need to specify which profile to use; see set profile.</p> <p>The default location for the AWS config file is <code>~/.aws/config</code>. You can specify another location using environment variable <code>AWS_CONFIG_FILE</code>.</p>"},{"location":"articles/credentials/#assume-a-role-with-credentials-from-another-profile","title":"Assume a role with credentials from another profile","text":"<p>You can assume a role, using initial credentials provided by another profile. To do this, specify in the AWS config file the role to assume in <code>role_arn</code> and the name of the other profile in <code>source_profile</code>.</p> <pre><code>[profile my-profile]\nrole_arn=arn:aws:iam::123456789012:role/my-role-name\nsource_profile=my-other-profile\n</code></pre> <p>Paws will look in both the AWS shared credentials file and the AWS config file for the source profile. The source profile can use any method to provide credentials.</p> <p>If you put these settings in a config profile other than <code>default</code>, you will need to specify which profile to use; see set profile.</p> <p>The default location for the AWS config file is <code>~/.aws/config</code>. You can specify another location using environment variable <code>AWS_CONFIG_FILE</code>.</p>"},{"location":"articles/credentials/#use-multifactor-authentication-when-assuming-a-role","title":"Use multifactor authentication when assuming a role","text":"<p>To use multifactor authentication (MFA) when assuming a role, specify in the AWS config file the MFA serial number in <code>mfa_serial</code>. When assuming the role, Paws will prompt you to enter your MFA token code.</p> <p>An example specifying MFA along with <code>source_profile</code> is below.</p> <pre><code>[profile my-profile]\nrole_arn=arn:aws:iam::123456789012:role/my-role-name\nsource_profile=my-other-profile\nmfa_serial=arn:aws:iam::123456789012:mfa/my-user-name\n</code></pre> <p>With multifactor authentication, Paws will ask you to re-enter your MFA token code whenever it has to refresh your credentials (currently, after one hour).</p> <p>If you put these settings in a config profile other than <code>default</code>, you will need to specify which profile to use; see set profile.</p> <p>The default location for the AWS config file is <code>~/.aws/config</code>. You can specify another location using environment variable <code>AWS_CONFIG_FILE</code>.</p>"},{"location":"articles/credentials/#use-aws-single-sign-on-sso","title":"Use AWS Single Sign-On (SSO)","text":"<p>NOTE: Currently, you must have the AWS CLI installed to use AWS SSO with Paws.</p> <p>To use AWS SSO to provide credentials for accessing AWS, you will need to  specify the SSO settings to use in the AWS config file, log in to SSO  using the AWS CLI, then tell Paws to use the profile.</p> <ol> <li> <p>Specify the SSO settings to use in the AWS config file in <code>~/.aws/config</code>,     e.g.</p> <pre><code>[profile my-dev-profile]\nsso_start_url = https://my-sso-portal.awsapps.com/start\nsso_region = us-east-1\nsso_account_id = 123456789011\nsso_role_name = readOnly\nregion = us-west-2\noutput = json\n</code></pre> </li> <li> <p>Log in to SSO using the AWS CLI.</p> <pre><code>aws sso login --profile my-dev-profile\n</code></pre> </li> <li> <p>Tell Paws to use the SSO profile. For alternate ways of specifying your    profile, see the set profile section. </p> <pre><code>Sys.setenv(AWS_PROFILE = \"my-dev-profile\")\n</code></pre> </li> </ol> <p>See also AWS's documentation about using the AWS CLI with SSO.</p>"},{"location":"articles/credentials/#set-region","title":"Set region","text":"<p>To use AWS, you must also set your AWS region. See below for common scenarios. For a reference to all available options, see the reference section.</p>"},{"location":"articles/credentials/#set-region-for-all-services-with-an-environment-variable","title":"Set region for all services with an environment variable","text":"<p>You can set the region for all services using an environment variable. Paws will look for region in both OS or R environment variables using either <code>AWS_REGION</code> or <code>AWS_DEFAULT_REGION</code>.</p> <p>You can use R to set region with the following command:</p> <pre><code>Sys.setenv(\nAWS_REGION = \"us-east-2\"\n)\n# or\nSys.setenv(\nAWS_DEFAULT_REGION = \"us-east-2\"\n)\n</code></pre>"},{"location":"articles/credentials/#get-region-from-the-aws-config-file","title":"Get region from the AWS config file","text":"<p>You can set the region using the AWS config file in <code>~/.aws/config</code>.</p> <pre><code>[profile my-profile]\nregion=us-east-2\n</code></pre> <p>If you put these settings in a config profile other than <code>default</code>, you will need to specify which profile to use; see set profile.</p> <p>The default location for the AWS config file is <code>~/.aws/config</code>. You can specify another location using environment variable <code>AWS_CONFIG_FILE</code>.</p>"},{"location":"articles/credentials/#set-region-for-an-individual-service","title":"Set region for an individual service","text":"<p>You can set region for an individual service by specifying it as an argument when you create the service object. This take precedence over region set using any other method.</p> <pre><code>svc &lt;- paws::svc(\nconfig = list(\nregion = \"us-east-2\"\n)\n)\n</code></pre> <p>In this example, <code>paws::svc</code> is a placeholder for an AWS service. Use a specific service instead, for example, <code>paws::s3</code>. Paws supports having multiple service objects with different regions.</p>"},{"location":"articles/credentials/#set-profile","title":"Set profile","text":"<p>You can store different settings together under different profiles in the AWS shared credentials and config files.</p> <p>If you do not specify a profile to use, Paws will use the <code>default</code> profile.</p> <p>You can specify a different profile to use using the <code>AWS_PROFILE</code> environment variable:</p> <pre><code>Sys.setenv(\nAWS_PROFILE = \"my-profile\"\n)\n</code></pre> <p>Or using the <code>profile</code> parameter to an individual service:</p> <pre><code>svc &lt;- paws::svc(\nconfig = list(\ncredentials = list(\nprofile = \"your profile\"\n)\n)\n)\n</code></pre> <p>In the AWS shared credentials, a separate profile looks like the following:</p> <pre><code>[default]\naws_access_key_id=default AWS access key\naws_secret_access_key=default AWS secret key\n\n[my-profile]\naws_access_key_id=my-profile AWS access key\naws_secret_access_key=my-profile AWS secret key\n</code></pre> <p>And in the AWS config file, it looks like the following. Note that in the config file, profile names other than default begin with <code>profile</code>.</p> <pre><code>[default]\nregion=us-east-1\n\n[profile my-profile]\nregion=us-east-2\n</code></pre>"},{"location":"articles/credentials/#reference","title":"Reference","text":""},{"location":"articles/credentials/#credential-and-option-locations-and-priority","title":"Credential and option locations and priority","text":"<p>Credentials and options can be set in the following locations. Paws will check them in this order:</p> <ol> <li>In settings provided to an individual service</li> <li>In environment variables</li> <li>In the AWS shared credentials file and     AWS config file</li> <li>In an EC2 instance or container IAM role</li> </ol> <p>This means that, for example, a service setting will take precedence over an environment variable, and an environment variable will take precedence over a setting in a config file.</p>"},{"location":"articles/credentials/#service-settings","title":"Service settings","text":"<p>Paws supports the following settings provided as arguments to a service:</p> <ul> <li> <p><code>access_key_id</code> - Specifies the AWS access key used as part of the   credentials to authenticate the request.</p> </li> <li> <p><code>secret_access_key</code> - Specifies the AWS secret key used as part of the   credentials to authenticate the request.</p> </li> <li> <p><code>session_token</code> - Specifies the session token value that is required if   you are using temporary security credentials that you retrieved directly   from AWS STS operations.</p> </li> <li> <p><code>expiration</code> - The expiration time of the credentials contained in the   parameters <code>access_key_id</code>, <code>secret_access_key</code>, and <code>session_token</code>. The   expiration time must be a date-time, e.g. <code>as.POSIXct(\"2001-02-03 04:05:06\")</code>.</p> </li> <li> <p><code>profile</code> - Specifies the name of the profile with the credentials and   options to use.</p> </li> <li> <p><code>region</code> - Specifies the AWS region to send the request to.</p> </li> </ul> <p>They must be provided to the service in the following structure. It is allowable to specify only some of the settings, e.g. only <code>region</code>.</p> <pre><code>svc &lt;- paws::svc(\nconfig = list(\ncredentials = list(\ncreds = list(\naccess_key_id = \"your AWS access key\",\nsecret_access_key = \"your AWS secret key\",\nsession_token = \"your session token\",\nexpiration = as.POSIXct(\"2001-02-03 04:05:06\")\n),\nprofile = \"your profile\"\n),\nregion = \"your region\"\n)\n)\n</code></pre>"},{"location":"articles/credentials/#environment-variables","title":"Environment variables","text":"<p>Paws supports the following settings in environment variables.</p> <ul> <li> <p><code>AWS_ACCESS_KEY_ID</code> - Specifies the AWS access key used as part of the   credentials to authenticate the request.</p> </li> <li> <p><code>AWS_CONFIG_FILE</code> - Specifies the location of the file used to store   configuration profiles. The default path is <code>~/.aws/config</code>.</p> </li> <li> <p><code>AWS_CREDENTIAL_EXPIRATION</code> - The expiration time of the credentials   contained in the environment variables <code>AWS_ACCESS_KEY_ID</code>,   <code>AWS_SECRET_ACCESS_KEY</code>, and <code>AWS_SESSION_TOKEN</code>. The expiration time must   be specified in ISO 8601 format, e.g. <code>\"2021-02-19T04:42:29Z\"</code>.</p> </li> <li> <p><code>AWS_EC2_METADATA_DISABLED</code> - Disables the use of the Amazon EC2 instance   metadata service (IMDS) when set to <code>\"true\"</code> (case insensitive) or <code>\"1\"</code>.</p> </li> <li> <p><code>AWS_PROFILE</code> - Specifies the name of the profile with the credentials and   options to use.</p> </li> <li> <p><code>AWS_REGION</code>/<code>AWS_DEFAULT_REGION</code> - Specifies the AWS region to send the request to.</p> </li> <li> <p><code>AWS_SECRET_ACCESS_KEY</code> - Specifies the AWS secret key used as part of the   credentials to authenticate the request.</p> </li> <li> <p><code>AWS_SESSION_TOKEN</code> - Specifies the session token value that is required if   you are using temporary security credentials that you retrieved directly   from AWS STS operations.</p> </li> <li> <p><code>AWS_SHARED_CREDENTIALS_FILES</code> - Specifies the location of the file used to   store access keys. The default path is <code>~/.aws/credentials</code>.</p> </li> </ul>"},{"location":"articles/credentials/#shared-credentials-file","title":"Shared credentials file","text":"<p>The default location for the AWS shared credentials file is <code>~/.aws/credentials</code>. You can specify another location using environment variable <code>AWS_SHARED_CREDENTIALS_FILE</code>.</p> <p>Paws supports the following settings in the AWS shared credentials file.</p> <ul> <li> <p><code>aws_access_key_id</code> - Specifies the AWS access key used as part of the   credentials to authenticate the request.</p> </li> <li> <p><code>aws_secret_access_key</code> - Specifies the AWS secret key used as part of the   credentials to authenticate the request.</p> </li> </ul>"},{"location":"articles/credentials/#config-file","title":"Config file","text":"<p>The default location for the AWS config file is <code>~/.aws/config</code>. You can specify another location using environment variable <code>AWS_CONFIG_FILE</code>.</p> <p>Paws supports the following settings in the AWS config file.</p> <ul> <li> <p><code>credential_process</code> - Specifies an external command to be run to generate   or retrieve authentication credentials. The command must return the   credentials in a specific format. For more information about how to use this   setting, see Sourcing credentials with an external process.</p> </li> <li> <p><code>credential_source</code> - Used within Amazon EC2 instances or EC2 containers to   specify where the SDK can find credentials to use to assume the role you   specified with the <code>role_arn</code> parameter. You cannot specify both   <code>source_profile</code> and <code>credential_source</code> in the same profile.</p> </li> </ul> <p>This parameter can have one of three values:</p> <pre><code>* `Environment` \u2013 Specifies that the SDK is to retrieve source credentials\n  from environment variables.\n\n* `Ec2InstanceMetadata` \u2013 Specifies that the SDK is to use the IAM role\n  attached to the EC2 instance profile to get source credentials.\n\n* `EcsContainer` \u2013 Specifies that the SDK is to use the IAM role attached\n  to the ECS container as source credentials.\n</code></pre> <ul> <li> <p><code>mfa_serial</code> - The identification number of an MFA device to use when   assuming a role. This is mandatory only if the trust policy of the role being   assumed includes a condition that requires MFA authentication. The value can   be either a serial number for a hardware device (such as GAHT12345678) or an   Amazon Resource Name (ARN) for a virtual MFA device (such as   <code>arn:aws:iam::123456789012:mfa/user</code>).</p> </li> <li> <p><code>region</code> - Specifies the AWS Region to send requests to for commands   requested using this profile.</p> </li> <li> <p><code>role_arn</code> - Specifies the Amazon Resource Name (ARN) of an IAM role that you   want to use to run SDK commands. You must also specify one of the   following parameters to identify the credentials that have permission to   assume this role: <code>source_profile</code>, <code>credential_source</code>.</p> </li> <li> <p><code>source_profile</code> - Specifies a named profile with long-term credentials that   the SDK can use to assume a role that you specified with the <code>role_arn</code>   parameter. You cannot specify both <code>source_profile</code> and <code>credential_source</code>   in the same profile.</p> </li> </ul>"},{"location":"docs/reference/","title":"Reference","text":"Package   Description   paws.analytics   Interface to 'Amazon Web Services' 'analytics' services,     including 'Elastic MapReduce' 'Hadoop' and 'Spark' big data service,     'Elasticsearch' search engine, and more.   paws.application.integration   Interface to 'Amazon Web Services' application integration     services, including 'Simple Queue Service' ('SQS') message queue,     'Simple Notification Service' ('SNS') publish/subscribe messaging, and     more.   paws.compute   Interface to 'Amazon Web Services' compute services,     including 'Elastic Compute Cloud' ('EC2'), 'Lambda'     functions-as-a-service, containers, batch processing, and more.   paws.cost.management   Interface to 'Amazon Web Services' cost management services,     including cost and usage reports, budgets, pricing, and more.   paws.customer.engagement   Interface to 'Amazon Web Services' customer engagement     services, including 'Simple Email Service', 'Connect' contact center     service, and more.   paws.database   Interface to 'Amazon Web Services' database services,     including 'Relational Database Service' ('RDS'), 'DynamoDB' 'NoSQL'     database, and more.   paws.developer.tools   Interface to 'Amazon Web Services' developer tools services,     including version control, continuous integration and deployment, and     more.   paws.end.user.computing   Interface to 'Amazon Web Services' end user computing     services, including collaborative document editing, mobile intranet,     and more.   paws.machine.learning   Interface to 'Amazon Web Services' machine learning services,     including 'SageMaker' managed machine learning service, natural     language processing, speech recognition, translation, and more.   paws.management   Interface to 'Amazon Web Services' management and governance     services, including 'CloudWatch' application and infrastructure     monitoring, 'Auto Scaling' for automatically scaling resources, and     more.   paws.networking   Interface to 'Amazon Web Services' networking and content     delivery services, including 'Route 53' Domain Name System service,     'CloudFront' content delivery, load balancing, and more.   paws.security.identity   Interface to 'Amazon Web Services' security, identity, and     compliance services, including the 'Identity &amp; Access Management'     ('IAM') service for managing access to services and resources, and     more.   paws.storage   Interface to 'Amazon Web Services' storage services,     including 'Simple Storage Service' ('S3') and more."},{"location":"examples/batch/","title":"batch","text":"<pre><code># Batch examples\n# Note: In some cases, you'll need to wait for a step to complete in your AWS\n# account before you can successfully run the next step.\n# To set up the Batch compute environment, get security group and subnet info\n# for the default VPC.\nec2 &lt;- paws::ec2()\ndefault_vpc &lt;- ec2$describe_vpcs(\nFilters = \"isDefault=true\"\n)$Vpcs[[1]]\nsecurity_group &lt;- ec2$describe_security_groups(\nFilters = sprintf(\"vpc-id=%s\", default_vpc$VpcId),\nGroupNames = \"default\"\n)$SecurityGroups[[1]]\nsubnets &lt;- ec2$describe_subnets(\nFilters = sprintf(\"vpc-id=%s\", default_vpc$VpcId)\n)$Subnets\n#-------------------------------------------------------------------------------\n# Set up an IAM role for Batch.\nrole_name &lt;- \"TestBatchServiceRole\"\npolicy_arn &lt;- \"arn:aws:iam::aws:policy/service-role/AWSBatchServiceRole\"\ntrust_policy &lt;- list(\nVersion = \"2012-10-17\",\nStatement = list(\nlist(\nEffect = \"Allow\",\nPrincipal = list(\nService = \"batch.amazonaws.com\"\n),\nAction = \"sts:AssumeRole\"\n)\n)\n)\niam &lt;- paws::iam()\nrole &lt;- iam$create_role(\nRoleName = role_name,\nAssumeRolePolicyDocument = jsonlite::toJSON(trust_policy, auto_unbox = TRUE)\n)\niam$attach_role_policy(\nRoleName = role_name,\nPolicyArn = policy_arn\n)\n#-------------------------------------------------------------------------------\nbatch &lt;- paws::batch()\n# Set up a compute environment: the resources on which Batch jobs will run.\nbatch$create_compute_environment(\ntype = \"MANAGED\",\ncomputeEnvironmentName = \"TestComputeEnvironment\",\ncomputeResources = list(\ntype = \"EC2\",\ndesiredvCpus = 1L,\nec2KeyPair = \"default\",\ninstanceRole = \"ecsInstanceRole\",\ninstanceTypes = \"optimal\",\nmaxvCpus = 128L,\nminvCpus = 0L,\nsecurityGroupIds = security_group$GroupId,\nsubnets = sapply(subnets, function(x) x$SubnetId)\n),\nserviceRole = role$Role$Arn,\nstate = \"ENABLED\"\n)\n# Set up a job queue for the compute environment.\nbatch$create_job_queue(\ncomputeEnvironmentOrder = list(\nlist(\ncomputeEnvironment = \"TestComputeEnvironment\",\norder = 1L\n)\n),\njobQueueName = \"TestJobQueue\",\npriority = 1L,\nstate = \"ENABLED\"\n)\n# Add an example job definition -- sleep 10 seconds.\njob_def &lt;- batch$register_job_definition(\ntype = \"container\",\ncontainerProperties = list(\ncommand = list(\n\"sleep\",\n\"10\"\n),\nimage = \"busybox\",\nmemory = 128L,\nvcpus = 1L\n),\njobDefinitionName = \"sleep10\"\n)\n# Submit a job.\njob &lt;- batch$submit_job(\njobDefinition = \"sleep10\",\njobName = \"Example\",\njobQueue = \"TestJobQueue\"\n)\nprint(job)\n# List the submitted job(s).\nbatch$list_jobs(\njobQueue = \"TestJobQueue\",\njobStatus = \"SUBMITTED\"\n)\n# Clean up. You may have to wait for some steps to complete.\nbatch$deregister_job_definition(jobDefinition = job_def$jobDefinitionArn)\nbatch$update_job_queue(\"TestJobQueue\", state = \"DISABLED\")\nbatch$delete_job_queue(\"TestJobQueue\")\nbatch$update_compute_environment(\"TestComputeEnvironment\", state = \"DISABLED\")\nbatch$delete_compute_environment(computeEnvironment = \"TestComputeEnvironment\")\niam$detach_role_policy(role_name, policy_arn)\niam$delete_role(role_name)\n</code></pre>"},{"location":"examples/comprehend/","title":"comprehend","text":"<pre><code># Comprehend natural language processing examples\ncomprehend &lt;- paws::comprehend()\n# Determine the dominant language(s) in a document.\ncomprehend$detect_dominant_language(\nText = \"Hello world!\"\n)\n# Determine the prevailing sentiment in a batch of documents.\ncomprehend$batch_detect_sentiment(\nTextList = list(\n\"Awesome!\",\n\"OK\",\n\"Meh\",\n\"Terrible!\"\n),\nLanguageCode = \"en\"\n)\ntext &lt;-\n\"Gatsby believed in the green light, the orgiastic future that year by\n   year recedes before us. It eluded us then, but that's no matter--\n   tomorrow we will run faster, stretch out our arms farther.... And one\n   fine morning-- So we beat on, boats against the current, borne back\n   ceaselessly into the past.\"\n# Find named entities in a document.\ncomprehend$detect_entities(\nText = text,\nLanguageCode = \"en\"\n)\n</code></pre>"},{"location":"examples/dynamodb/","title":"dynamodb","text":"<pre><code># DynamoDB examples\ndynamodb &lt;- paws::dynamodb()\n# Create a DynamoDB table.\nresp &lt;- dynamodb$create_table(\nAttributeDefinitions = list(\nlist(\n\"AttributeName\" = \"Artist\",\n\"AttributeType\" = \"S\"\n),\nlist(\n\"AttributeName\" = \"SongTitle\",\n\"AttributeType\" = \"S\"\n)\n),\nKeySchema = list(\nlist(\n\"AttributeName\" = \"Artist\",\n\"KeyType\" = \"HASH\"\n),\nlist(\n\"AttributeName\" = \"SongTitle\",\n\"KeyType\" = \"RANGE\"\n)\n),\nProvisionedThroughput = list(\n\"ReadCapacityUnits\" = 5,\n\"WriteCapacityUnits\" = 5\n),\nTableName = \"Music\"\n)\n# List our DynamoDB tables.\ntables &lt;- dynamodb$list_tables()\n# Delete the table just created.\ndynamodb$delete_table(\"Music\")\n</code></pre>"},{"location":"examples/ec2/","title":"ec2","text":"<pre><code># EC2 examples\nec2 &lt;- paws::ec2()\n# Start an EC2 instance.\nresp &lt;- ec2$run_instances(\nImageId = \"ami-f973ab84\",\nInstanceType = \"t2.micro\",\nMinCount = 1,\nMaxCount = 1,\nKeyName = \"default\",\nPlacement = list(AvailabilityZone = \"us-east-1a\"),\nTagSpecifications = list(\nlist(\nResourceType = \"instance\",\nTags = list(\nlist(Key = \"webserver\", Value = \"production\"))\n),\nlist(\nResourceType = \"volume\",\nTags = list(\nlist(Key = \"cost-center\", Value = \"cc123\")\n)\n)\n)\n)\n# List our instances.\ninstances &lt;- ec2$describe_instances()\n# Terminate the instance we previously started.\nec2$terminate_instances(\nInstanceIds = resp$Instances[[1]]$InstanceId\n)\n</code></pre>"},{"location":"examples/error_handling/","title":"error_handling","text":"<pre><code># Error Handling Examples\nlibrary(paws)\ns3_svc &lt;- s3()\n# Attempt a request that will certainly fail and catch the error object.\nb1 &lt;- tryCatch(s3_svc$list_objects_v2(Bucket = \"not_a_bucket_alskfj\", MaxKeys =2), error = function(e) e)\nb1$message\n# &gt; \"NoSuchBucket (HTTP 404). The specified bucket does not exist\"\n# Look at the details of the error\nattributes(b1)\n# Output:\n#&gt; $names\n#&gt; [1] \"message\"\n#&gt; $class\n#&gt; [1] \"http_404\"   \"http_400\"   \"http_error\" \"error\"      \"condition\"\n#&gt; $status_code\n#&gt; [1] 404\n#&gt;\n#&gt; $error_response\n#&gt; $error_response$Code\n#&gt; [1] \"NoSuchBucket\"\n#&gt; $error_response$Message\n#&gt; [1] \"The specified bucket does not exist\"\n#&gt; $error_response$BucketName\n#&gt; [1] \"not_a_bucket_alskfj\"\n#&gt; $error_response$RequestId\n#&gt; [1] \"3568524444199D04\"\n#&gt; $error_response$HostId\n#&gt; [1] \"P2te81nv444441hoXsdKxUEFzwhB+J4444499APIKGLKpn8X/LaOioBS/a229v93uYOMXkFehIc=\"\n# Retry after a 1 second wait on 50X errors:\nresponse &lt;- NULL\nattempt_count &lt;- 0\nwhile (is.null(response) | inherits(response, \"http_500\") | attempt_count &lt; 3){\nattempt_count &lt;- attempt_count + 1\nresponse &lt;- tryCatch(s3_svc$list_objects_v2(Bucket = \"this-is-a-real-bucket\", MaxKeys =2), error = function(e) e)\nif(inherits(response, \"http_500\") &amp; attempt_count &lt; 3){\nprint(paste0(\"Request failed with 500 error and message: \", response$message))\nprint(\"Retrying after 1 second sleep\")\nSys.sleep(1)\n} else if (inherits(response, \"error\")){\n# Re-raise the error object on non-500 error or 500 error with maxed retries\nstop(response)\n}\n}\n</code></pre>"},{"location":"examples/how_to_access_federated_api_using_saml2_and_adfs/","title":"how_to_access_federated_api_using_saml2_and_adfs","text":"<pre><code>##########################################################################\n# modified from: https://aws.amazon.com/blogs/security/how-to-implement-federated-api-and-cli-access-using-saml-2-0-and-ad-fs/\n##########################################################################\n##########################################################################\n# Packages required \n##########################################################################\nlibrary(httr)\nlibrary(xml2)\n# getPass is used within the function when password isn't provided\n# base64enc is used to decode samlassertion\n##########################################################################\n# wrapper to access \nadfs_saml2 &lt;- function(adfs_url, region, username = NULL, password = NULL){\n# Get the federated credentials from the user\nif(is.null(username)) username = readline(\"Username:\")\nif(is.null(password)) password = getPass::getPass()\nset_config(config(ssl_verifypeer = 0L))\n# get first page\nformresponse = GET(adfs_url)\non.exit(handle_reset(adfs_url))\nidpauthformsubmiturl = formresponse$url\nformsoup  = content(formresponse)\npayload = list()\nfor (inputtag in xml_find_all(formsoup, \".//INPUT|.//input\")){\nname = if(is.na(xml_attr(inputtag, \"name\"))) \"\" else xml_attr(inputtag, \"name\")\nvalue = if(is.na(xml_attr(inputtag, \"value\"))) \"\" else xml_attr(inputtag, \"value\")\nif(grepl(\"user\", tolower(name)))\npayload[[name]] = username\nelse if(grepl(\"email\", tolower(name)))\npayload[[name]] = username\nelse if(grepl(\"pass\", tolower(name)))\npayload[[name]] = password\nelse\npayload[[name]] = value\n}\nfor (inputtag in xml_find_all(formsoup,('.//FORM|.//form'))){\naction = xml_attr(inputtag, 'action')\nloginid = xml_attr(inputtag, 'id')\nif (!is.na(action) &amp;&amp; loginid == \"loginForm\"){\nparsedurl = parse_url(adfs_url)\nidpauthformsubmiturl = paste0(parsedurl$scheme,\"://\",parsedurl$hostname,action)\n}\n}\nCookies = unlist(as.list(formresponse$cookies))\n# get samlassertion\nresponse = POST(idpauthformsubmiturl, body = payload, set_cookies(.cookies = Cookies), encode=\"form\")\nsoup = content(response)\nSAMLResponse = NA\nfor (inputtag in xml_find_all(soup,('.//input'))){\nname = if(!is.na(xml_attr(inputtag, 'name'))) xml_attr(inputtag, 'name') else \"\"\nif(name == 'SAMLResponse')\nSAMLResponse = xml_attr(inputtag, 'value')\n}\nif(is.na(SAMLResponse)) stop('Response did not contain a valid SAML assertion')\n# decode saml assertion so that can get roles for user to choose from\nroot = readBin(base64enc::base64decode(SAMLResponse), \"character\") saml2attribute = read_xml(root)\n# get correct level to iterate over\nchild3 = xml_children(xml_children(xml_children(saml2attribute)))\n# get aws roles\nawsroles= list()\nfor(saml in child3){\nif(isTRUE(xml_attr(saml, \"Name\") == \"https://aws.amazon.com/SAML/Attributes/Role\"))\nawsroles = c(awsroles, xml_text(xml_children(saml)))\n}\n# safe way to present roles to user (hides saml roles)\naws_saml_role = lapply(seq_along(awsroles), function(i){\naws_role_split = unlist(strsplit(awsroles[[i]], \",\"))\nsaml = grepl(\"saml-provider\", aws_role_split)\nnames(aws_role_split) = c(\"role_arn\", \"principal_arn\")[as.numeric(saml)+1]\naws_role_split}\n)\n# asks user which role to choose\nwriteLines(\"Please choose the role you would like to assume:\")\nfor(i in seq_along(aws_saml_role)){\nwriteLines(sprintf(\"[%i]: %s\",i , aws_saml_role[[i]][\"role_arn\"]))\n}\nchoosen_role = as.numeric(readline(\"Selection: \"))\naws_saml_role=aws_saml_role[[choosen_role]]\nlist(SamlRole = aws_saml_role, SAMLResponse = SAMLResponse)\n}\n##########################################################################\n# Variables \n# region: The default AWS region that this script will connect \n# to for all API calls \nregion = 'us-west-2' # idpentryurl: The initial URL that starts the authentication process. \nidpentryurl = 'https://&lt;fqdn&gt;/adfs/ls/IdpInitiatedSignOn.aspx?loginToRp=urn:amazon:webservices' ##########################################################################\n##########################################################################\n# connect to adfs and get saml2 assertion\nobj = adfs_saml2(idpentryurl, region)\ncred= paws::sts()$assume_role_with_saml(RoleArn = obj$SamlRole[\"role_arn\"], PrincipalArn = obj$SamlRole[\"principal_arn\"],\nSAMLAssertion = obj$SAMLResponse)\n##########################################################################\n# Use the AWS STS token to list all of the S3 buckets\nconfig = list(\ncredentials = list(\ncreds = list(\naccess_key_id = cred$Credentials$AccessKeyId,\nsecret_access_key = cred$Credentials$SecretAccessKey,\nsession_token = cred$Credentials$SessionToken\n)\n)\n)\n# connect to AWS S3 using temporary SAML credentials\nS3= paws::s3(config)\n# list all s3 buckets\nsapply(S3$list_buckets()$Buckets, function(x) x$Name)\n</code></pre>"},{"location":"examples/lambda/","title":"lambda","text":"<pre><code># Lambda examples\n#-------------------------------------------------------------------------------\n# Create a Lambda function package to upload.\ncode &lt;- 'exports.handler = async (event, context) =&gt; { return \"Hello!\"; };'\npath &lt;- tempdir()\njs_file &lt;- file.path(path, \"lambda.js\")\nwriteLines(code, js_file)\nzip_file &lt;- file.path(path, \"lambda.zip\")\nutils::zip(zip_file, js_file, flags = \"-j\")\nzip_contents &lt;- readBin(zip_file, \"raw\", n = 1e5)\n#-------------------------------------------------------------------------------\n# Set up an IAM role for the Lambda function.\nrole_name &lt;- \"MyRole\"\npolicy_arn &lt;- \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\ntrust_policy &lt;- list(\nVersion = \"2012-10-17\",\nStatement = list(\nlist(\nEffect = \"Allow\",\nPrincipal = list(\nService = \"lambda.amazonaws.com\"\n),\nAction = \"sts:AssumeRole\"\n)\n)\n)\niam &lt;- paws::iam()\nrole &lt;- iam$create_role(\nRoleName = role_name,\nAssumeRolePolicyDocument = jsonlite::toJSON(trust_policy, auto_unbox = TRUE)\n)\niam$attach_role_policy(\nRoleName = role_name,\nPolicyArn = policy_arn\n)\n#-------------------------------------------------------------------------------\nlambda &lt;- paws::lambda()\n# Create the Lambda function.\nlambda$create_function(\nCode = list(ZipFile = zip_contents),\nFunctionName = \"MyFunction\",\nHandler = \"lambda.handler\",\nRole = role$Role$Arn,\nRuntime = \"nodejs8.10\"\n)\n# Run the function.\nresp &lt;- lambda$invoke(\"MyFunction\")\n# Print the function's output.\nrawToChar(resp$Payload)\n# List available functions.\nlambda$list_functions()\n# Clean up.\nlambda$delete_function(\"MyFunction\")\niam$detach_role_policy(role_name, policy_arn)\niam$delete_role(role_name)\n</code></pre>"},{"location":"examples/s3/","title":"s3","text":"<pre><code># Simple Storage Service (S3) examples\ns3 &lt;- paws::s3()\n# Set the name of a new bucket\n# We're just using the uuid package to ensure a unique bucket name. You do not\n# have to use it and can input any unique bucket name you would like instead\nbucket_name &lt;- paste0(\"paws-example-\", uuid::UUIDgenerate())\n# Create a bucket in us-east-1\ns3$create_bucket(\nBucket = bucket_name\n)\n# List your buckets\ns3$list_buckets()\n# Create a data.frame that we will upload to S3\nexample_df &lt;- data.frame(foo = c(\"hello\", \"world\"), bar = c(1, 2))\n# Save it as an RDS file\nfile_name1 &lt;- \"s3_example.rds\"\nsaveRDS(example_df, file = file_name1)\n################################################################################\n# The following section is only recommended if using paws.common               #\n# versions &lt;= 0.3.6.                                                           #\n# For paws.common versions &lt;= 0.3.6 put_object requires the Body parameter to  #\n# be a vector of raw bytes. Therefore if you are using an older version of     #\n# paws.common you must take the following steps to upload a file to s3. The    #\n# following code works for versions of paws.common &gt;= 0.3.7 as well, but the   #\n# same task can be completed more easily as shown in the section further below #\n# for versions greater or equal to 0.3.7.                                      #\n################################################################################\n# Load the file as a raw binary\nread_file &lt;- file(file_name1, \"rb\")\ns3_example &lt;- readBin(read_file, \"raw\", n = file.size(file_name1))\nclose(read_file)\n# Upload file to s3\ns3$put_object(\nBody = s3_example,\nBucket = bucket_name,\nKey = file_name1\n)\n################################################################################\n# For paws.common versions &gt;= 0.3.7 we can pass a file path directly to the    #\n# Body parameter of put_object. This is the recommended way for users using    #\n# newer versions of paws.common.                                               #\n################################################################################\n# Upload file to s3\ns3$put_object(\nBody = file_name1,\nBucket = bucket_name,\nKey = file_name1\n)\n################################################################################\n# List objects in the bucket\ns3$list_objects(Bucket = bucket_name)\n# Download the file and store the output in a variable\ns3_download &lt;- s3$get_object(\nBucket = bucket_name,\nKey = file_name1\n)\n# Write output to file\nfile_name2 &lt;- \"s3_download.rds\"\nwriteBin(s3_download$Body, con = file_name2)\n# Test the new data.frame to ensure it works\nreadRDS(file_name2)\n# Alternatively, read the data frame directly, without writing to disk.\nrequire(magrittr)\ns3_download$Body %&gt;% rawConnection() %&gt;% gzcon %&gt;% readRDS\n################################################################################\n# Read a CSV from S3.\n################################################################################\n# Upload a CSV file.\nfile_name3 &lt;- \"s3_example.csv\"\nwrite.csv(example_df, file_name3)\n# Upload the CSV file to S3.\ns3$put_object(\nBody = file_name3,\nBucket = bucket_name,\nKey = file_name3\n)\n# Get the CSV file from S3.\ns3_download &lt;- s3$get_object(\nBucket = bucket_name,\nKey = file_name3\n)\n# Read the CSV in from disk.\nfile_name4 &lt;- \"s3_download.csv\"\nwriteBin(s3_download$Body, con = file_name4)\nread.csv(file_name4)\n# Alternatively, read in the CSV directly from S3.\nrequire(magrittr)\ns3_download$Body %&gt;% rawToChar %&gt;% read.csv(text = .)\n# Cleanup\ns3$delete_object(Bucket = bucket_name, Key = file_name1)\ns3$delete_object(Bucket = bucket_name, Key = file_name3)\ns3$delete_bucket(Bucket = bucket_name)\nfile.remove(file_name1)\nfile.remove(file_name2)\nfile.remove(file_name3)\nfile.remove(file_name4)\n</code></pre>"},{"location":"examples/s3_multipart_upload/","title":"s3_multipart_upload","text":"<pre><code># Upload a file to S3 using multipart upload.\ns3 &lt;- paws::s3()\nfile &lt;- \"&lt;path to the file to upload&gt;\"\nbucket &lt;- \"&lt;your S3 bucket&gt;\"\nkey &lt;- \"&lt;name of the file once it is uploaded into your S3 bucket&gt;\"\n#' Upload a file to S3 using multipart upload\n#'\n#' @param client A Paws S3 client object, e.g. from `paws::s3()`.\n#' @param file The path to the file to be uploaded.\n#' @param bucket The name of the S3 bucket to be uploaded to, e.g. `my-bucket`.\n#' @param key The name to assign to the file in the S3 bucket, e.g. `path/to/file`.\nupload &lt;- function(client, file, bucket, key) {\nmultipart &lt;- client$create_multipart_upload(\nBucket = bucket,\nKey = key\n)\nresp &lt;- NULL\non.exit({\nif (is.null(resp) || inherits(resp, \"try-error\")) {\nclient$abort_multipart_upload(\nBucket = bucket,\nKey = key,\nUploadId = multipart$UploadId\n)\n}\n})\nresp &lt;- try({\nparts &lt;- upload_multipart_parts(client, file, bucket, key, multipart$UploadId)\nclient$complete_multipart_upload(\nBucket = bucket,\nKey = key,\nMultipartUpload = list(Parts = parts),\nUploadId = multipart$UploadId\n)\n})\nreturn(resp)\n}\nupload_multipart_parts &lt;- function(client, file, bucket, key, upload_id) {\nfile_size &lt;- file.size(file)\nmegabyte &lt;- 2^20\npart_size &lt;- 5 * megabyte\nnum_parts &lt;- ceiling(file_size / part_size)\ncon &lt;- base::file(file, open = \"rb\")\non.exit({\nclose(con)\n})\npb &lt;- utils::txtProgressBar(min = 0, max = num_parts)\nparts &lt;- list()\nfor (i in 1:num_parts) {\npart &lt;- readBin(con, what = \"raw\", n = part_size)\npart_resp &lt;- client$upload_part(\nBody = part,\nBucket = bucket,\nKey = key,\nPartNumber = i,\nUploadId = upload_id\n)\nparts &lt;- c(parts, list(list(ETag = part_resp$ETag, PartNumber = i)))\nutils::setTxtProgressBar(pb, i)\n}\nclose(pb)\nreturn(parts)\n}\n# Upload the file.\nupload(s3, file, bucket, key)\n</code></pre>"},{"location":"examples/s3_select_object_content/","title":"s3_select_object_content","text":"<pre><code># This example shows how to get data from S3 using a SQL query and the\n# select_object_content operation. For more information, see\n# https://docs.aws.amazon.com/AmazonS3/latest/API/API_SelectObjectContent.html.\ns3 &lt;- paws::s3()\nbucket &lt;- \"my-bucket\"\nfile &lt;- \"my-file.csv\"\nquery &lt;- \"select * from s3object where x = '1'\"\n# Run a SQL query on data in a CSV in S3, and get the query's result set.\nresult &lt;- s3$select_object_content(\nBucket = bucket,\nKey = file,\nExpression = query,\nExpressionType = \"SQL\",\nInputSerialization = list(\n'CSV' = list(\nFileHeaderInfo = \"USE\"\n)\n),\nOutputSerialization = list(\n'CSV'= list(\nQuoteFields = \"ASNEEDED\"\n)\n)\n)\n# Convert the resulting CSV data into an R data frame.\ndata &lt;- read.csv(text = result$Payload$Records$Payload, header = FALSE, col.names = \"x\")\n</code></pre>"},{"location":"examples/sns/","title":"sns","text":"<pre><code># Simple Notification Service examples\nsns &lt;- paws::sns()\n# Create a topic to which we can send notifications.\ntopic &lt;- sns$create_topic(\"ExampleTopic\")\n# List our topics.\nsns$list_topics()\n# Subscribe an email address to the topic.\n# You'll have to confirm the subscription to receive emails.\nsns$subscribe(\nTopicArn = topic$TopicArn,\nProtocol = \"email\",\nEndpoint = \"user@example.com\"\n)\n# Publish a message to the topic.\nsns$publish(\nMessage = \"Hello world!\",\nTopicArn = topic$TopicArn\n)\n# Delete the example topic.\nsns$delete_topic(topic$TopicArn)\n</code></pre>"},{"location":"examples/sqs/","title":"sqs","text":"<pre><code># Simple Queue Service examples\nsqs &lt;- paws::sqs()\n# Create a queue.\nsqs &lt;- sqs$create_queue(\nQueueName = \"ExampleQueue\"\n)\n# Add a message to the queue.\nsqs$send_message(\nQueueUrl = sqs$QueueUrl,\nMessageBody = \"foo\"\n)\n# Get the queue's attributes.\nsqs$get_queue_attributes(\nQueueUrl = sqs$QueueUrl,\nAttributeNames = \"All\"\n)\n# Get the next message from the queue.\nmsg &lt;- sqs$receive_message(\nQueueUrl = sqs$QueueUrl\n)\n# Delete the message.\nsqs$delete_message(\nQueueUrl = sqs$QueueUrl,\nReceiptHandle = msg$Messages[[1]]$ReceiptHandle\n)\n# Delete the queue.\nsqs$delete_queue(\nQueueUrl = sqs$QueueUrl\n)\n</code></pre>"},{"location":"examples/textract/","title":"textract","text":"<pre><code># Using R with Amazon Web Services for document analysis\n# https://aws.amazon.com/blogs/opensource/using-r-with-amazon-web-services-for-document-analysis/\n# This R program shows how you can use AWS with R to create a data pipeline for\n# extracting data from PDFs for future processing, using Textract, S3,\n# Relational Database Service (RDS).\n# The PDF document is from the Greenbook projections, a set of economic \n# projections made by the Federal Reserve from 1966 to the present.  They are\n# available as a collection of PDFs from the Philadelphia Federal Reserve at:\n# https://www.philadelphiafed.org/research-and-data/real-time-center/greenbook-data/pdf-data-set\n# This R program expects that you have:\n#   - An S3 bucket with PDFs\n#   - An RDS PostgreSQL database with IAM authentication\n#   - A user, instance, or container with IAM permissions to access Textract\n#     and your RDS database\n#   - R, and the packages paws, DBI, and RPostgres\n#-------------------------------------------------------------------------------\n# The location of the first Greenbook Projections PDF document in S3.\nbucket &lt;- \"my-bucket\"\nfile &lt;- \"GS-1966-01-11.pdf\"\ntextract &lt;- paws::textract()\n#-------------------------------------------------------------------------------\n#-------------------------------------------------------------------------------\n#-------------------------------------------------------------------------------\n# Get a PDF document's tables using Amazon Textract.\n# --------------------------------------------------\nanalyze_document &lt;- function(bucket, file) {\n# Start analyzing the PDF.\nresp &lt;- textract$start_document_analysis(\nDocumentLocation = list(\nS3Object = list(Bucket = bucket, Name = file)\n),\nFeatureTypes = \"TABLES\"\n)\n# Check that the analysis is done and get the result.\ncount &lt;- 0\nwhile (count &lt; 30 &amp;&amp; (!exists(\"result\") || result$JobStatus == \"IN_PROGRESS\")) {\nSys.sleep(1)\nresult &lt;- textract$get_document_analysis(\nJobId = resp$JobId\n)\n# If the result has multiple parts, get the remaining parts.\nnext_token &lt;- result$NextToken\nwhile (length(next_token) &gt; 0) {\nnext_result &lt;- textract$get_document_analysis(\nJobId = resp$JobId,\nNextToken = next_token\n)\nresult$Blocks &lt;- c(result$Blocks, next_result$Blocks)\nnext_token &lt;- next_result$NextToken\n}\ncount &lt;- count + 1\n}\nreturn(result)\n}\nanalysis &lt;- analyze_document(bucket, file)\n#-------------------------------------------------------------------------------\n#-------------------------------------------------------------------------------\n#-------------------------------------------------------------------------------\n# Turn the Textract analysis result into matrices.\n# ------------------------------------------------\n# Get all children for a given block.\nget_children &lt;- function(block, data) {\nif (length(block$Relationships) == 0) {\nreturn(list())\n}\nidx &lt;- which(sapply(block$Relationships, function(x) x$Type) == \"CHILD\")\nif (!idx) {\nreturn(list())\n}\nchild_ids &lt;- block$Relationships[[idx]]$Ids\nresult &lt;- data[child_ids]\nreturn(result)\n}\n# Get all tables for a given document analysis returned by `analyze_document`.\nget_tables &lt;- function(analysis) {\nblocks &lt;- analysis$Blocks\nnames(blocks) &lt;- sapply(blocks, function(x) x$Id)\ntables &lt;- list()\nfor (block in blocks) {\nif (block$BlockType == \"TABLE\") {\ncells &lt;- get_children(block, blocks)\nrows &lt;- max(sapply(cells, function(x) x$RowIndex))\ncols &lt;- max(sapply(cells, function(x) x$ColumnIndex))\ntable &lt;- matrix(nrow = rows, ncol = cols)\n# 1. Go through a table's cells one-by-one\nfor (cell in cells) {\n# 2. Get the cell's contents\nwords &lt;- get_children(cell, blocks)\ntext &lt;- paste(sapply(words, function(x) x$Text), collapse = \" \")\n# 3. Insert the cell contents into the matrix\nrow &lt;- cell$RowIndex\ncol &lt;- cell$ColumnIndex\ntable[row, col] &lt;- text\n}\ntables &lt;- c(tables, list(table))\n}\n}\nreturn(tables)\n}\ntables &lt;- get_tables(analysis)\n#-------------------------------------------------------------------------------\n#-------------------------------------------------------------------------------\n#-------------------------------------------------------------------------------\n# Upload our results to our database.\n# -----------------------------------\n# Connect to the database using an IAM authentication token.\nrds &lt;- paws::rds()\ntoken &lt;- rds$build_auth_token(\"myhost:5432\", \"us-east-1\", \"david\")\ncon &lt;- DBI::dbConnect(\nRPostgres::Postgres(),\nhost = \"myhost\", port = 5432, dbname = \"mydb\",\nuser = \"david\", password = token\n)\n# Create rows for each table to insert into the database.\ndatabase_rows &lt;- data.frame(\ndocument = \"GS-1966-01-11.pdf\", table_num = 1:length(tables),\ndata = sapply(tables, jsonlite::toJSON)\n)\n# Store the tables in the database.\nDBI::dbAppendTable(con, name = \"tables\", value = database_rows)\n</code></pre>"}]}